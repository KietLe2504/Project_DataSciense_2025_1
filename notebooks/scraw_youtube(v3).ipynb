{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vy50k_9A8LJh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy50k_9A8LJh",
        "outputId": "859d2d53-d0ae-4000-af3b-cd744d282b9f"
      },
      "outputs": [],
      "source": [
        "#%pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29ae18b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "API_KEYS = [\n",
        "]\n",
        "\n",
        "CSV_FILE = \"1697_channels_to_scrape.csv\"\n",
        "OUTPUT_NPY = \"youtube_comments.npy\"\n",
        "MAX_COMMENTS_PER_CHANNEL = 20000\n",
        "MAX_RESULTS_PER_REQUEST = 100\n",
        "\n",
        "current_key_index = 0\n",
        "youtube = None\n",
        "\n",
        "all_rows = []   # [channel_name, channel_id, video_name, video_id, author, comment_text, likes, time, comment_id]\n",
        "\n",
        "\n",
        "def build_youtube_service(api_key):\n",
        "    return build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "\n",
        "def print_current_key():\n",
        "    print(f\"Using API key #{current_key_index + 1}/{len(API_KEYS)}\")\n",
        "\n",
        "\n",
        "def init_youtube():\n",
        "    global youtube, current_key_index\n",
        "    current_key_index = 0\n",
        "    youtube = build_youtube_service(API_KEYS[current_key_index])\n",
        "    print_current_key()\n",
        "\n",
        "\n",
        "def switch_to_next_key():\n",
        "    global youtube, current_key_index\n",
        "    current_key_index = (current_key_index + 1) % len(API_KEYS)\n",
        "    youtube = build_youtube_service(API_KEYS[current_key_index])\n",
        "    print_current_key()\n",
        "\n",
        "\n",
        "def is_fatal_key_error(http_error: HttpError) -> bool:\n",
        "    fatal_reasons = {\n",
        "        \"quotaExceeded\",\n",
        "        \"dailyLimitExceeded\",\n",
        "        \"keyInvalid\",\n",
        "        \"ipRefererBlocked\",\n",
        "        \"rateLimitExceeded\",\n",
        "    }\n",
        "    try:\n",
        "        error_json = json.loads(http_error.content.decode(\"utf-8\"))\n",
        "        errors = error_json.get(\"error\", {}).get(\"errors\", [])\n",
        "        if errors:\n",
        "            reason = errors[0].get(\"reason\", \"\")\n",
        "            if reason in fatal_reasons:\n",
        "                return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    msg = str(http_error)\n",
        "    return any(r in msg for r in fatal_reasons)\n",
        "\n",
        "\n",
        "def comment_threads_list_with_rotation(**kwargs):\n",
        "    global youtube, current_key_index\n",
        "\n",
        "    tried_keys = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            return youtube.commentThreads().list(**kwargs).execute()\n",
        "        except HttpError as e:\n",
        "            if is_fatal_key_error(e):\n",
        "                print(\n",
        "                    f\"[API key #{current_key_index + 1}] \"\n",
        "                    f\"HttpError (fatal for this key): {e}\"\n",
        "                )\n",
        "                tried_keys += 1\n",
        "                if tried_keys >= len(API_KEYS):\n",
        "                    raise RuntimeError(\n",
        "                        \"T·∫•t c·∫£ API key ƒë√£ h·∫øt quota ho·∫∑c g·∫∑p l·ªói kh√¥ng th·ªÉ d√πng.\"\n",
        "                    )\n",
        "                switch_to_next_key()\n",
        "                continue\n",
        "            raise\n",
        "\n",
        "\n",
        "def save_numpy(rows):\n",
        "    data_array = np.array(rows, dtype=object)\n",
        "    np.save(OUTPUT_NPY, data_array)\n",
        "    print(f\"Saved numpy file: {OUTPUT_NPY} with shape {data_array.shape}\")\n",
        "\n",
        "\n",
        "def fetch_comments_for_video(video_id, max_comments_for_this_video):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(comments) < max_comments_for_this_video:\n",
        "        remaining = max_comments_for_this_video - len(comments)\n",
        "        max_results = min(MAX_RESULTS_PER_REQUEST, remaining)\n",
        "\n",
        "        response = comment_threads_list_with_rotation(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=max_results,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\",\n",
        "        )\n",
        "\n",
        "        items = response.get(\"items\", [])\n",
        "        if not items:\n",
        "            break\n",
        "\n",
        "        for item in items:\n",
        "            tlc = item.get(\"snippet\", {}).get(\"topLevelComment\", {})\n",
        "            snippet = tlc.get(\"snippet\", {})\n",
        "\n",
        "            raw_text = snippet.get(\"textDisplay\", \"\") or snippet.get(\"textOriginal\", \"\")\n",
        "\n",
        "            clean_text = (\n",
        "                raw_text.replace(\"\\r\\n\", \" \")\n",
        "                        .replace(\"\\n\", \" \")\n",
        "                        .replace(\"\\r\", \" \")\n",
        "            )\n",
        "\n",
        "            author = snippet.get(\"authorDisplayName\", \"\")\n",
        "            like_count = snippet.get(\"likeCount\", 0)\n",
        "            time_str = snippet.get(\"publishedAt\") or snippet.get(\"updatedAt\", \"\")\n",
        "            comment_id = tlc.get(\"id\", \"\")\n",
        "\n",
        "            comments.append((author, clean_text, like_count, time_str, comment_id))\n",
        "\n",
        "            if len(comments) >= max_comments_for_this_video:\n",
        "                break\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return comments\n",
        "\n",
        "\n",
        "def main():\n",
        "    global all_rows\n",
        "    all_rows.clear()  # reset global list at the start of a run\n",
        "\n",
        "    init_youtube()\n",
        "\n",
        "    df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "    df = df.rename(columns={\n",
        "        \"channel name\": \"channel_name\",\n",
        "        \"channel id\": \"channel_id\",\n",
        "        \"video name\": \"video_name\",\n",
        "        \"video id\": \"video_id\"\n",
        "    })\n",
        "\n",
        "    grouped = df.groupby([\"channel_id\", \"channel_name\"], sort=False)\n",
        "\n",
        "    total_comments = 0\n",
        "\n",
        "    for (channel_id, channel_name), group in grouped:\n",
        "        channel_comment_count = 0\n",
        "\n",
        "        if \"Comment Count\" in group.columns:\n",
        "            group_sorted = group.sort_values(\"Comment Count\", ascending=False)\n",
        "        else:\n",
        "            group_sorted = group\n",
        "\n",
        "        for _, row in group_sorted.iterrows():\n",
        "            if channel_comment_count >= MAX_COMMENTS_PER_CHANNEL:\n",
        "                break\n",
        "\n",
        "            video_name = row[\"video_name\"]\n",
        "            video_id = row[\"video_id\"]\n",
        "            remaining_for_channel = MAX_COMMENTS_PER_CHANNEL - channel_comment_count\n",
        "\n",
        "            try:\n",
        "                video_comments = fetch_comments_for_video(\n",
        "                    video_id,\n",
        "                    remaining_for_channel\n",
        "                )\n",
        "            except RuntimeError as e:\n",
        "                print(f\"FATAL ERROR (API keys) khi x·ª≠ l√Ω video {video_id}: {e}\")\n",
        "                save_numpy(all_rows)\n",
        "                print(f\"Channel {channel_name} ({channel_id}): {channel_comment_count} comments\")\n",
        "                print(f\"TOTAL COMMENTS: {total_comments}\")\n",
        "                return\n",
        "            except Exception as e:\n",
        "                print(f\"ERROR khi x·ª≠ l√Ω video {video_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "            for author, comment_text, like_count, time_str, comment_id in video_comments:\n",
        "                all_rows.append([\n",
        "                    channel_name,\n",
        "                    channel_id,\n",
        "                    video_name,\n",
        "                    video_id,\n",
        "                    author,\n",
        "                    comment_text,\n",
        "                    like_count,\n",
        "                    time_str,\n",
        "                    comment_id,\n",
        "                ])\n",
        "\n",
        "            channel_comment_count += len(video_comments)\n",
        "            total_comments += len(video_comments)\n",
        "\n",
        "        print(f\"Channel {channel_name} ({channel_id}): {channel_comment_count} comments\")\n",
        "\n",
        "    save_numpy(all_rows)\n",
        "    print(f\"TOTAL COMMENTS: {total_comments}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb800db",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_numpy1(rows):\n",
        "    data_array = np.array(rows, dtype=object)\n",
        "    np.save(\"youtube_comments_backup.npy\", data_array)\n",
        "    print(f\"Saved numpy file: {OUTPUT_NPY} with shape {data_array.shape}\")\n",
        "\n",
        "save_numpy1(all_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51rHCZzxTOzU",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "51rHCZzxTOzU",
        "outputId": "b30b4cf1-4486-4359-e05c-229a7626b7cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13954012, 5)\n",
            "[['21 Savage' 'UCOjEHmBKwdS7joWpW0VrXkg'\n",
            "  '21 Savage - a lot (Official Video) ft. J. Cole' 'DmWWqogr_r8'\n",
            "  'J Cole ruined this straight killed the vibe.. this would‚Äôve had billions of views']\n",
            " ['21 Savage' 'UCOjEHmBKwdS7joWpW0VrXkg'\n",
            "  '21 Savage - a lot (Official Video) ft. J. Cole' 'DmWWqogr_r8'\n",
            "  'Nov.14,2025??']\n",
            " ['21 Savage' 'UCOjEHmBKwdS7joWpW0VrXkg'\n",
            "  '21 Savage - a lot (Official Video) ft. J. Cole' 'DmWWqogr_r8' 'Trash']\n",
            " ...\n",
            " ['Gesic' 'UCEyoqQQK4vWWZZ57banT6Kg'\n",
            "  'Neha kakkar or Guru Randhava Comedy video | Talking Tom Comedy video ‡•§ ‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ç ‡§ï‡•ã‡§Æ‡•á‡§°‡•Ä ‡§ï‡•â‡§≤'\n",
            "  '6aKpJAC_69s' 'Nice']\n",
            " ['Gesic' 'UCEyoqQQK4vWWZZ57banT6Kg'\n",
            "  'Neha kakkar or Guru Randhava Comedy video | Talking Tom Comedy video ‡•§ ‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ç ‡§ï‡•ã‡§Æ‡•á‡§°‡•Ä ‡§ï‡•â‡§≤'\n",
            "  '6aKpJAC_69s' 'Beautifulüíì NiceüíìüíÉüé∂üï∫üëçü§©']\n",
            " ['Gesic' 'UCEyoqQQK4vWWZZ57banT6Kg'\n",
            "  'Neha kakkar or Guru Randhava Comedy video | Talking Tom Comedy video ‡•§ ‡§¨‡§ø‡§≤‡•ç‡§≤‡•Ç ‡§ï‡•ã‡§Æ‡•á‡§°‡•Ä ‡§ï‡•â‡§≤'\n",
            "  '6aKpJAC_69s' 'Khatarnak']]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.load('youtube_comments.npy', allow_pickle=True)\n",
        "print(data.shape)\n",
        "print(data)\n",
        "\n",
        "# [channel_name, channel_id, video_name, video_id, author, comment_text, likes, time, comment_id]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08721fb",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
